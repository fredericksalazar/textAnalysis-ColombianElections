{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer archivos PDF y convertir en texto\n",
    "\n",
    "Este modulo del programa se encarga de leer los archivos en formato PDF de las diferentes campañas y convertir ese contenido en texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.pdfdocument import PDFDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos las funciones esenciales que usaremos en el proceso de limpieza de datos\n",
    "\n",
    "def leer_texto(path_archivo):\n",
    "    \"\"\"obtiene un string con el texto completro de un archivo\n",
    "\n",
    "    Returns:\n",
    "        _string_: \n",
    "        string: texto de un archivos\n",
    "    \"\"\"\n",
    "    \n",
    "    archivo = open(path_archivo, 'r')\n",
    "\n",
    "    text = ''\n",
    "\n",
    "    while(True):\n",
    "        linea = archivo.readline()\n",
    "        text = text+linea\n",
    "        if not linea:\n",
    "            break\n",
    "    \n",
    "    archivo.close\n",
    "    \n",
    "    return text\n",
    "\n",
    "def depurar_texto(token_texto):\n",
    "    \"\"\"A partir de una lista de tokens con cadenas de texto\n",
    "       crea un nuevo texto solo con aquellos tokens de caracteres\n",
    "       para ello se aplica la validación isalpha()\n",
    "\n",
    "    Args:\n",
    "        token_texto (_list_): lista de tokens con palabras\n",
    "\n",
    "    Returns:\n",
    "        string: texto depurado solo con caracteres validos.\n",
    "    \"\"\"\n",
    "    \n",
    "    texto_depurado = ''\n",
    "    \n",
    "    for palabra in token_texto:\n",
    "        \n",
    "        palabra = palabra.replace('\\n', '')\n",
    "        palabra = palabra.replace('-', ' ')\n",
    "        palabra = re.sub(r'[^\\w\\s]','', palabra)\n",
    "        palabra = palabra.replace('\\x0c',' ')\n",
    "        \n",
    "        texto_depurado = texto_depurado+' '+palabra.lower()\n",
    "    \n",
    "    return texto_depurado\n",
    "\n",
    "def depurar_texto_fajardo(token_texto):\n",
    "    \"\"\"A partir de una lista de tokens con cadenas de texto\n",
    "       crea un nuevo texto solo con aquellos tokens de caracteres\n",
    "       para ello se aplica la validación isalpha()\n",
    "\n",
    "    Args:\n",
    "        token_texto (_list_): lista de tokens con palabras\n",
    "\n",
    "    Returns:\n",
    "        string: texto depurado solo con caracteres validos.\n",
    "    \"\"\"\n",
    "    \n",
    "    texto_depurado = ''\n",
    "    \n",
    "    for palabra in token_texto:\n",
    "        \n",
    "        palabra = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', palabra, flags=re.MULTILINE)\n",
    "        palabra = palabra.replace('\\x0c',' ')\n",
    "        palabra = re.sub(r'[^\\w\\s]','', palabra)\n",
    "        palabra = palabra.replace('\\n', ' ')\n",
    "        palabra = palabra.replace('cid', '')\n",
    "        \n",
    "        if palabra.isalpha():\n",
    "            texto_depurado = texto_depurado+' '+palabra.lower()\n",
    "    \n",
    "    return texto_depurado\n",
    "\n",
    "def depurar_texto_rodolfo(token_texto):\n",
    "    \"\"\"A partir de una lista de tokens con cadenas de texto\n",
    "       crea un nuevo texto solo con aquellos tokens de caracteres\n",
    "       para ello se aplica la validación isalpha()\n",
    "\n",
    "    Args:\n",
    "        token_texto (_list_): lista de tokens con palabras\n",
    "\n",
    "    Returns:\n",
    "        string: texto depurado solo con caracteres validos.\n",
    "    \"\"\"\n",
    "    \n",
    "    texto_depurado = ''\n",
    "    \n",
    "    for palabra in token_texto:\n",
    "        \n",
    "        palabra = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', palabra, flags=re.MULTILINE)\n",
    "        palabra = re.sub(r'[^\\w\\s]','', palabra)\n",
    "        palabra = palabra.replace('\\n', '')\n",
    "        palabra = palabra.replace('\\x0c',' ')\n",
    "        palabra = palabra.replace('\\xa0',' ')\n",
    "        \n",
    "        texto_depurado = texto_depurado+''+palabra.lower()\n",
    "    \n",
    "    return texto_depurado\n",
    "\n",
    "def depurar_texto_federico(token_texto):\n",
    "    \"\"\"A partir de una lista de tokens con cadenas de texto\n",
    "       crea un nuevo texto solo con aquellos tokens de caracteres\n",
    "       para ello se aplica la validación isalpha()\n",
    "\n",
    "    Args:\n",
    "        token_texto (_list_): lista de tokens con palabras\n",
    "\n",
    "    Returns:\n",
    "        string: texto depurado solo con caracteres validos.\n",
    "    \"\"\"\n",
    "    \n",
    "    texto_depurado = ''\n",
    "    \n",
    "    for palabra in token_texto:\n",
    "        \n",
    "        palabra = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', palabra, flags=re.MULTILINE)\n",
    "        palabra = palabra.replace('\\n', '')\n",
    "        #palabra = palabra.replace('-', ' ')\n",
    "        palabra = re.sub(r'[^\\w\\s]','', palabra)\n",
    "        palabra = palabra.replace('\\x0c',' ')\n",
    "        \n",
    "        texto_depurado = texto_depurado+' '+palabra.lower()\n",
    "    \n",
    "    return texto_depurado\n",
    "\n",
    "def quitar_palabras_1(texto):\n",
    "    \n",
    "    if len(texto)>1:\n",
    "        return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_petro = './archivos/petro.pdf'\n",
    "plan_fajardo = './archivos/fajardo.pdf'\n",
    "plan_rodolfo = './archivos/rodolfo.pdf'\n",
    "plan_federico = './archivos/federico.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se lee el texto de cada uno de los pdf para extraer el texto y convertirlo en txt\n",
    "\n",
    "textoPetro = extract_text(plan_petro)\n",
    "textoFajardo = extract_text(plan_fajardo)\n",
    "textoRodolfo = extract_text(plan_rodolfo)\n",
    "textoFederico = extract_text(plan_federico)\n",
    "\n",
    "#Guardamos el archivo txt de cada candidato\n",
    "fileText = open(plan_petro+'.txt', 'w')\n",
    "fileText.write(textoPetro)\n",
    "fileText.close()\n",
    "\n",
    "fileText = open(plan_fajardo+'.txt', 'w')\n",
    "fileText.write(textoFajardo)\n",
    "fileText.close()\n",
    "\n",
    "fileText = open(plan_rodolfo+'.txt', 'w')\n",
    "fileText.write(textoRodolfo)\n",
    "fileText.close()\n",
    "\n",
    "fileText = open(plan_federico+'.txt', 'w')\n",
    "fileText.write(textoFederico)\n",
    "fileText.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de texto\n",
    "\n",
    "De acuerdo al contenido y estructura de cada uno de los archivos pdf convertidos a txt, procedemos a realizar una limpieza inicial para normalizar un poco los datos. en este caso vamos a definir unas reglas generales para los documentos:\n",
    "\n",
    "- texto en minusculas\n",
    "- se eliminan signos de puntuacion\n",
    "- se trabajará con palabras de tamaño mayor a 2\n",
    "- se extraen referencias a paginas web\n",
    "- los documentos limpios seguiran el siguiente patron: autor_clean.pdf.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se procesa archivo de petro\n",
    "\n",
    "archivo_petro = leer_texto('./archivos/petro.pdf.txt')\n",
    "\n",
    "doc_petro_depurado = depurar_texto(archivo_petro.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se procesa archivo de fajardo\n",
    "\n",
    "archivo_fajardo = leer_texto('./archivos/fajardo.pdf.txt')\n",
    "\n",
    "doc_fajardo_depurado = depurar_texto_fajardo(archivo_fajardo.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se procesa archivo de fajardo\n",
    "\n",
    "archivo_rodolfo = leer_texto('./archivos/rodolfo.pdf.txt')\n",
    "\n",
    "doc_rodolfo_depurado = depurar_texto_rodolfo(archivo_rodolfo)\n",
    "\n",
    "doc_rodolfo_depurado_lis = doc_rodolfo_depurado.split(' ')\n",
    "\n",
    "doc_rodolfo_depurado_fin = \"\"\n",
    "\n",
    "for palabra in doc_rodolfo_depurado_lis:\n",
    "    if len(palabra)>1:\n",
    "        doc_rodolfo_depurado_fin = doc_rodolfo_depurado_fin+' '+palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_federico = leer_texto('./archivos/federico.pdf.txt')\n",
    "\n",
    "doc_federico_depurado = depurar_texto_federico(archivo_federico.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los textos previamente depurados son almacenados para mantener su trazabilidad.\n",
    "\n",
    "dep_petro = open('./archivos/petro_clean.pdf.txt','w')\n",
    "dep_petro.write(doc_petro_depurado)\n",
    "\n",
    "dep_fajardo = open('./archivos/fajardo_clean.pdf.txt','w')\n",
    "dep_fajardo.write(doc_fajardo_depurado)\n",
    "\n",
    "dep_rodolfo = open('./archivos/rodolfo_clean.pdf.txt','w')\n",
    "dep_rodolfo.write(doc_rodolfo_depurado_fin)\n",
    "\n",
    "dep_federico = open('./archivos/federico_clean.pdf.txt','w')\n",
    "dep_federico.write(doc_federico_depurado)\n",
    "\n",
    "dep_petro.close()\n",
    "dep_fajardo.close()\n",
    "dep_rodolfo.close()\n",
    "dep_federico.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
